<!-- hide -->
# Naive Bayes - Gu√≠a paso a paso
<!-- endhide -->

- Comprender un dataset nuevo.
- Procesarlo aplicando un an√°lisis exploratorio (EDA).
- Modelar los datos utilizando un Naive Bayes.
- Analizar los resultados y optimizar el modelo.

<how-to-start>
  
## üå± C√≥mo iniciar este proyecto

Sigue las siguientes instrucciones:

1. Crea un nuevo repositorio basado en el [proyecto de Machine Learning](https://github.com/4GeeksAcademy/machine-learning-python-template) [haciendo clic aqu√≠](https://github.com/4GeeksAcademy/machine-learning-python-template/generate).
2. Abre el repositorio creado recientemente en Codespace usando la [extensi√≥n del bot√≥n de Codespace](https://docs.github.com/es/codespaces/developing-in-codespaces/creating-a-codespace-for-a-repository#creating-a-codespace-for-a-repository).
3. Una vez que el VSCode del Codespace haya terminado de abrirse, comienza tu proyecto siguiendo las instrucciones a continuaci√≥n.

</how-to-start>

## üöõ C√≥mo entregar este proyecto

Una vez que hayas terminado de resolver el caso pr√°ctico, aseg√∫rate de confirmar tus cambios, haz push a tu repositorio y ve a 4Geeks.com para subir el enlace del repositorio.

## üìù Instrucciones

### An√°lisis de sentimientos

Los modelos Naive Bayes son muy √∫tiles cuando queremos analizar sentimientos, clasificar textos en t√≥picos o recomendaciones, ya que las caracter√≠sticas de estos desaf√≠os cumplen muy bien con los supuestos te√≥ricos y metodol√≥gicos del modelo.

En este proyecto practicar√°s con un conjunto de datos para crear un clasificador de rese√±as de la tienda de Google Play.

#### Paso 1: Carga del conjunto de datos

El conjunto de datos se puede encontrar en esta carpeta de proyecto bajo el nombre `playstore_reviews.csv`. Puedes cargarlo en el c√≥digo directamente desde el sigiente enlace: 

```text
https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv
```
O descargarlo y a√±adirlo a mano en tu repositorio. En este conjunto de datos encontrar√°s las siguientes variables:

- `package_name`. Nombre de la aplicaci√≥n m√≥vil (categ√≥rico)
- `review`. Comentario sobre la aplicaci√≥n m√≥vil (categ√≥rico)
- `polarity`. Variable de clase (0 o 1), siendo 0 un comentario negativo y 1, positivo (categ√≥rico num√©rico)


#### Paso 2: Procesamiento del texto

### ¬øPor qu√© no podemos usar texto plano en Machine Learning?

Los algoritmos de Machine Learning no pueden trabajar directamente con texto: **necesitan n√∫meros**. Por eso, debemos convertir los comentarios (reviews) en representaciones num√©ricas. Este proceso se llama **vectorizaci√≥n del texto**.

Una de las t√©cnicas m√°s sencillas y efectivas para esto es el **modelo de bolsa de palabras (Bag of Words)**, que se implementa en Python con CountVectorizer.

#### ¬øQu√© hace `CountVectorizer`?

`CountVectorizer` transforma cada comentario en un vector que indica **cu√°ntas veces aparece cada palabra**. Por ejemplo:

```text
Comentario original: "Me encanta esta app"
Vector resultante:    [1, 1, 1]  ‚Üê (una vez ‚Äúme‚Äù, una vez ‚Äúencanta‚Äù, una vez ‚Äúesta‚Äù)
```

Adem√°s, permite eliminar las **palabras vac√≠as** (como ‚Äúde‚Äù, ‚Äúla‚Äù, ‚Äúy‚Äù) usando el par√°metro `stop_words="english"`.

Ahora s√≠, los pasos concretos para preparar los datos son los siguientes:

- Eliminar espacios y convertir todo a min√∫sculas:

    ```python
    df["review"] = df["review"].str.strip().str.lower()
    ```

- Eliminar la columna que no aporta informaci√≥n predictiva:

    ```python
    df = df.drop("package_name", axis=1)
    ```

- Dividir los datos en entrenamiento y prueba:

    ```python
    from sklearn.model_selection import train_test_split

    X = df["review"]
    y = df["polarity"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    ```

- Vectorizar el texto usando CountVectorizer:

    ```python
    from sklearn.feature_extraction.text import CountVectorizer

    vectorizer = CountVectorizer(stop_words="english")

    X_train_vec = vectorizer.fit_transform(X_train).toarray()
    X_test_vec = vectorizer.transform(X_test).toarray()
    ```

Una vez hayamos terminado tendremos listas las predictoras para entrenar el modelo.


#### Paso 3: Construye un naive bayes

Comienza a resolver el problema implementando un modelo del que tendr√°s que elegir cu√°l de las tres implementaciones utilizar: `GaussianNB`, `MultinomialNB` o `BernoulliNB`, seg√∫n lo que hemos estudiado en el m√≥dulo. Prueba ahora a entrenarlo con las dos otras implementaciones y confirma si el modelo que has elegido es el adecuado.

#### Paso 4: Optimiza el modelo anterior

Despu√©s de entrenar el modelo en sus tres implementaciones, elige la mejor opci√≥n y trata de optimizar sus resultados con un random forest, si es posible.

#### Paso 5: Guarda el modelo

Almacena el modelo en la carpeta correspondiente.

#### Paso 6: Explora otras alternativas

¬øQu√© otros modelos de los que hemos estudiado podr√≠as utilizar para intentar superar los resultados de un Naive Bayes? Argum√©ntalo y entrena el modelo.

> Nota: Tambi√©n incorporamos muestras de soluci√≥n en `./solution.ipynb` que te sugerimos honestamente que solo uses si est√°s atascado por m√°s de 30 minutos o si ya has terminado y quieres compararlo con tu enfoque.


## üöÄ Haz visible tu trabajo

Ahora es tu turno de comunicar en tu **LinkedIn** lo que tu modelo aprendi√≥ del lenguaje humano.

### ¬øQu√© compartir?

Public√° una reflexi√≥n o insight poderoso que surja del an√°lisis de rese√±as. Puede ser sobre c√≥mo la gente se expresa al escribir cr√≠ticas, qu√© palabras predicen con mayor fuerza una opini√≥n negativa, o c√≥mo tu modelo logra entender el ‚Äúsentimiento‚Äù detr√°s de las palabras.

Tambi√©n pod√©s acompa√±arlo con una visualizaci√≥n, como las palabras m√°s comunes en cr√≠ticas negativas, o ejemplos donde tu modelo acert√≥ (o fall√≥) sorprendentemente.

---

### ‚ú® Ejemplos posteables

> **¬øTu IA detecta frustraci√≥n?**  
> Entren√© un modelo de clasificaci√≥n con Naive Bayes para detectar sentimientos en rese√±as de apps.  
> Descubr√≠ que palabras como *‚Äúbug‚Äù*, *‚Äúcrashes‚Äù*, *‚Äúads‚Äù* aparecen de forma desproporcionada en comentarios negativos.  
> Lo incre√≠ble: el modelo acert√≥ con m√°s del 90% de precisi√≥n sin haber ‚Äúentendido‚Äù ni una sola palabra.  
> Solo estad√≠stica pura. ü§ñüí¨



> **La emoci√≥n tambi√©n se entrena**  
> ¬øPuede una IA saber si est√°s feliz con una app?  
> Despu√©s de entrenar un clasificador con m√°s de 50.000 rese√±as, descubr√≠ que palabras como *‚Äúlove‚Äù*, *‚Äúhelpful‚Äù* y *‚Äúeasy‚Äù* son predictores clave de rese√±as positivas.  
> Con solo unas l√≠neas de texto, el modelo sabe si sos fan o hater.  
> #MachineLearning #NLP


## üöõ C√≥mo entregar este proyecto

Una vez que hayas terminado de resolver el caso pr√°ctico, aseg√∫rate de confirmar tus cambios, haz push a tu repositorio y ve a 4Geeks.com para subir el enlace del repositorio.

